{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc76282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data from MHC Excel files\n",
    "\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "\n",
    "# Configuration\n",
    "prefix = '/master/abagwell/workspace/MHC/'\n",
    "# For applying parental information for haplotype inference\n",
    "demographics = '/master/abagwell/variant-analysis/resources/rhesus/pedigree/demographics.tsv'  # Last updated 2025-12-11\n",
    "# For applying manual corrections to haplotyping\n",
    "modifications_file = '/master/abagwell/workspace/MHC/modifications.diplotype.tsv'\n",
    "# For updating batch names to simpler, standardized names.\n",
    "# First column should be called \"Old\" with the original names.\n",
    "# And the second column called \"New\" with the updated names.\n",
    "batch_map = '/master/abagwell/workspace/MHC/batch_map.tsv'\n",
    "\n",
    "# Read in list of input files\n",
    "# File contains a columns for batch names and Excel file names\n",
    "#input_files = pl.read_csv(prefix + 'input_files.tsv', separator='\\t', comment_prefix=\"#\")\n",
    "input_files = pl.read_csv(prefix + 'input_files.combined.tsv', separator='\\t', comment_prefix=\"#\")\n",
    "\n",
    "# Values to treat as nulls\n",
    "null_values = [\"\", \" \", \"?\", \"A-unk\", \"DPA-unk\", \"DPB-unk\", \"DQA-unk\", \"DQA_unk\", \"DQB?\"]\n",
    "\n",
    "\n",
    "# Parse the \"Abbreviated Haplotypes\" sheet from each Excel file\n",
    "def parse_excel(file):\n",
    "    return pl.read_excel(f\"{prefix}input/{file}\", sheet_name='Abbreviated Haplotypes',\n",
    "        #engine='xlsx2csv', engine_options={'null_values': null_values}\n",
    "        ).rename({\n",
    "            # Rename columns to make different columns names across files match\n",
    "            'Client ID': 'Animal ID',\n",
    "            'client_id': 'Animal ID',\n",
    "            'OC ID': 'GS ID',\n",
    "            'File Source': 'Batch',\n",
    "            'Mamu-A Haplotype 1': 'MHC-A Haplotype 1',\n",
    "            'Mamu-A Haplotype 2': 'MHC-A Haplotype 2',\n",
    "            'Mamu-B Haplotype 1': 'MHC-B Haplotype 1',\n",
    "            'Mamu-B Haplotype 2': 'MHC-B Haplotype 2',\n",
    "            'Mamu-DRB Haplotype 1': 'MHC-DRB Haplotype 1',\n",
    "            'Mamu-DRB Haplotype 2': 'MHC-DRB Haplotype 2',\n",
    "            'Mamu-DQA Haplotype 1': 'MHC-DQA Haplotype 1',\n",
    "            'Mamu-DQA Haplotype 2': 'MHC-DQA Haplotype 2',\n",
    "            'Mamu-DQB Haplotype 1': 'MHC-DQB Haplotype 1',\n",
    "            'Mamu-DQB Haplotype 2': 'MHC-DQB Haplotype 2',\n",
    "            'Mamu-DPA Haplotype 1': 'MHC-DPA Haplotype 1',\n",
    "            'Mamu-DPA Haplotype 2': 'MHC-DPA Haplotype 2',\n",
    "            'Mamu-DPB Haplotype 1': 'MHC-DPB Haplotype 1',\n",
    "            'Mamu-DPB Haplotype 2': 'MHC-DPB Haplotype 2',\n",
    "            'Mamu-I Haplotype 1': 'MHC-I Haplotype 1',\n",
    "            'Mamu-I Haplotype 2': 'MHC-I Haplotype 2',\n",
    "        }, strict=False\n",
    "        ).select(\n",
    "            # Select only relevant columns\n",
    "            'Animal ID', cs.starts_with('Batch'), 'GS ID',\n",
    "            cs.starts_with('MHC-') & cs.matches(r'.*Haplotype [12]$'),\n",
    "        ).drop_nulls(\n",
    "            # Drop rows with missing Animal ID\n",
    "            \"Animal ID\"\n",
    "        ).filter(\n",
    "            # Remove rows without any haplotypes\n",
    "            # TODO: Only works when all input files have all these columns. Need to generalize\n",
    "            ~(pl.col('MHC-A Haplotype 1').is_null()\n",
    "              & pl.col('MHC-A Haplotype 2').is_null()\n",
    "              & pl.col('MHC-B Haplotype 1').is_null()\n",
    "              & pl.col('MHC-B Haplotype 2').is_null()\n",
    "              & pl.col('MHC-DRB Haplotype 1').is_null()\n",
    "              & pl.col('MHC-DRB Haplotype 2').is_null()\n",
    "              & pl.col('MHC-DQA Haplotype 1').is_null()\n",
    "              & pl.col('MHC-DQB Haplotype 2').is_null()\n",
    "              & pl.col('MHC-DPA Haplotype 1').is_null()\n",
    "              & pl.col('MHC-DPB Haplotype 2').is_null()\n",
    "            #   & pl.col('MHC-I Haplotype 1').is_null()\n",
    "            #   & pl.col('MHC-I Haplotype 2').is_null()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "# .filter(\n",
    "#         # Remove rows that aren't animals\n",
    "#         #~pl.col(\"Animal ID\").is_in([\"Totals\", \"Ave\"])\n",
    "#         ~pl.col(\"GS ID(s)\").is_in([\"Totals\", \"Ave\"])\n",
    "#     )\n",
    "\n",
    "# dfs = []\n",
    "# for batch, file in zip(input_files[\"batch\"].to_list(), input_files[\"file\"].to_list()):\n",
    "#     try:\n",
    "#         dfs.append(parse_excel(file).with_columns(\n",
    "#             Batch = pl.lit(batch\n",
    "#         )))\n",
    "#     except:\n",
    "#         print(f\"File {file} is not in correct format.\")\n",
    "\n",
    "# Read the batch mapping file\n",
    "batches = pl.read_csv(batch_map, separator='\\t', comment_prefix=\"#\")\n",
    "\n",
    "dfs = []\n",
    "for batch, file in zip(input_files[\"batch\"].to_list(), input_files[\"file\"].to_list()):\n",
    "    df = parse_excel(file)\n",
    "    # Check if already has \"Batch\" column\n",
    "    if \"Batch\" in df.columns:\n",
    "        # Update the batch names\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"Batch\").replace(old=batches[\"Old\"], new=batches[\"New\"]).alias(\"Batch\")\n",
    "        )\n",
    "    else:\n",
    "        # Add the batch column\n",
    "        df = df.with_columns(\n",
    "            Batch = pl.lit(batch)\n",
    "        )\n",
    "    try:\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(f\"File {file} is not in correct format.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A key to convert 2017 haplotype names to 2021 haplotype names\n",
    "haplotype_key = pl.read_csv(prefix + 'haplotype_key.tsv', separator='\\t')\n",
    "mapping = dict(\n",
    "    zip(\n",
    "        list(haplotype_key['2017 Haplotype']), list(haplotype_key['2021 Haplotype'])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Not always as simple as this\n",
    "# mappings={\n",
    "#     'a': '.01',\n",
    "#     'b': '.02',\n",
    "#     'c': '.03',\n",
    "#     'd': '.04',\n",
    "#     'e': '.05',\n",
    "#     'f': '.06',\n",
    "#     'g': '.07',\n",
    "# }\n",
    "\n",
    "nested = pl.concat(dfs, how='diagonal_relaxed').with_columns(\n",
    "    # Update to 2021 nomenclature of abbreviated haplotypes\n",
    "    # TODO: Deal with the abnormal haplotype values like those with \"{}\", \"rec\", etc.\n",
    "    pl.col(\"MHC-A Haplotype 1\").replace(mapping),\n",
    "    pl.col(\"MHC-A Haplotype 2\").replace(mapping),\n",
    "    pl.col(\"MHC-B Haplotype 1\").replace(mapping),\n",
    "    pl.col(\"MHC-B Haplotype 2\").replace(mapping),\n",
    ").with_columns(\n",
    "    # Combine the two haplotypes for each gene into arrays\n",
    "    # TODO: Generalize this to work for any gene\n",
    "    pl.concat_arr(['MHC-A Haplotype 1', 'MHC-A Haplotype 2']).alias('MHC-A'),\n",
    "    pl.concat_arr(['MHC-B Haplotype 1', 'MHC-B Haplotype 2']).alias('MHC-B'),\n",
    "    pl.concat_arr(['MHC-DRB Haplotype 1', 'MHC-DRB Haplotype 2']).alias('MHC-DRB'),\n",
    "    pl.concat_arr(['MHC-DQA Haplotype 1', 'MHC-DQA Haplotype 2']).alias('MHC-DQA'),\n",
    "    pl.concat_arr(['MHC-DQB Haplotype 1', 'MHC-DQB Haplotype 2']).alias('MHC-DQB'),\n",
    "    pl.concat_arr(['MHC-DPA Haplotype 1', 'MHC-DPA Haplotype 2']).alias('MHC-DPA'),\n",
    "    pl.concat_arr(['MHC-DPB Haplotype 1', 'MHC-DPB Haplotype 2']).alias('MHC-DPB'),\n",
    ").drop(\n",
    "    # Remove the split haplotype columns\n",
    "    cs.ends_with('Haplotype 1') | cs.ends_with('Haplotype 2')\n",
    ").rename(\n",
    "    # Rename Id column to match demographics file\n",
    "    {'Animal ID': 'Indiv'}\n",
    ")\n",
    "\n",
    "# # Join all parsed data with pedigree information\n",
    "# nested = pl.read_csv(\n",
    "#     # Add pedigree information\n",
    "#     demographics,\n",
    "#     separator='\\t', comment_prefix=\"#\", columns=[\"Id\", \"Sire\", \"Dam\"], schema_overrides={\n",
    "#         \"Id\": pl.String,\n",
    "#         \"Sire\": pl.String,\n",
    "#         \"Dam\": pl.String,\n",
    "#     }\n",
    "# ).join(\n",
    "#     # Concatenate the parsed excel files\n",
    "#     pl.concat(dfs, how='diagonal_relaxed'),\n",
    "#     left_on=\"Id\", right_on=\"Animal ID\", how=\"left\"\n",
    "\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_unk = r'unk|Unk| |[(?]'\n",
    "\n",
    "unpivoted = nested.unpivot(\n",
    "    # Unpivot the MHC haplotype columns into rows\n",
    "    cs.starts_with('MHC-'),\n",
    "    index=['Indiv', 'Batch', 'GS ID'],\n",
    "    variable_name='Gene',\n",
    "    value_name='Diplotype'\n",
    ").with_columns(\n",
    "    # Set previously inferred to null (will be inferred later),\n",
    "    # as well as any containing \"?\" or \"unk\" or \"Unk\"\n",
    "    pl.col(\"Diplotype\").arr.eval(\n",
    "        pl.when(pl.element().str.contains(regex_unk)).then(\n",
    "            None\n",
    "        ).otherwise(\n",
    "            pl.element()\n",
    "        )\n",
    "    ).alias(\"Diplotype\")\n",
    ").with_columns(\n",
    "    pl.col(\"Diplotype\").arr.eval(\n",
    "        pl.when(pl.element().str.contains(regex_unk)).then(\n",
    "            None #pl.lit(\"Inferred\")\n",
    "        ).when(pl.element().is_not_null()).then(\n",
    "            pl.lit(\"Empirical\"))\n",
    "    ).alias(\"Haplotype Method\")\n",
    ")\n",
    "\n",
    "unpivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddd206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace certain haplotypes with a table of manual corrections\n",
    "modifications = pl.read_csv(modifications_file, separator='\\t', comment_prefix=\"#\", schema_overrides={\n",
    "    'Indiv': pl.String,\n",
    "}).with_columns(\n",
    "    # Convert diplotypes into lists\n",
    "    pl.col(\"Old Diplotype\").str.split(\",\").list.to_array(2),\n",
    "    pl.col(\"New Diplotype\").str.split(\",\").list.to_array(2),\n",
    "    pl.lit([\"Modified\", \"Modified\"]).alias(\"Haplotype Method\").list.to_array(2),\n",
    "    pl.lit(\"Modified\").alias(\"Batch\"),\n",
    "    pl.lit(None).alias(\"GS ID\"),\n",
    ").rename({\n",
    "    'New Diplotype': 'Diplotype'\n",
    "}).select(\"Indiv\", \"Batch\", 'GS ID', \"Gene\", \"Diplotype\", \"Haplotype Method\")\n",
    "\n",
    "#modifications\n",
    "\n",
    "\n",
    "# Old approach which duplicated rows\n",
    "# modified = pl.concat([\n",
    "#     # Keep rows that don't need modification\n",
    "#     unpivoted.join(modifications, on=['Indiv', 'Gene'], how='anti'),\n",
    "#     modifications\n",
    "# ])\n",
    "\n",
    "# Apply modifications\n",
    "modified = unpivoted.join(modifications, on=['Indiv', 'Gene'], how='left').with_columns(\n",
    "    # Use modified diplotype if exists, otherwise keep original\n",
    "    pl.when(pl.col(\"Diplotype_right\").is_null()).then(\n",
    "        pl.col(\"Diplotype\")\n",
    "    ).when(pl.col(\"Diplotype\").is_not_null()).then(\n",
    "        pl.col(\"Diplotype_right\")\n",
    "    ).alias(\"Diplotype\"),\n",
    "    # TODO: Fix Haplotype Method since it applies to both haplotypes and not just one\n",
    "    pl.when(pl.col(\"Haplotype Method_right\").is_null()).then(\n",
    "        pl.col(\"Haplotype Method\")\n",
    "    ).when(pl.col(\"Haplotype Method_right\").is_not_null()).then(\n",
    "        pl.col(\"Haplotype Method_right\")\n",
    "    ).alias(\"Haplotype Method\")\n",
    ").drop(cs.ends_with(\"_right\"))\n",
    "\n",
    "# Join all parsed data with pedigree information\n",
    "modified = pl.read_csv(\n",
    "    # Add pedigree information\n",
    "    demographics,\n",
    "    separator='\\t', comment_prefix=\"#\", columns=[\"Id\", \"Sire\", \"Dam\"], schema_overrides={\n",
    "        \"Id\": pl.String,\n",
    "        \"Sire\": pl.String,\n",
    "        \"Dam\": pl.String,\n",
    "    }\n",
    ").join(\n",
    "    # Concatenate the parsed excel files\n",
    "    modified,\n",
    "    left_on=\"Id\", right_on=\"Indiv\", how=\"left\"\n",
    ")\n",
    "# .rename({\n",
    "#     # TODO: Remove this here and in later parts\n",
    "#     'Diplotype': 'Haplotype'\n",
    "# })\n",
    "\n",
    "modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlier attempt to keep empirical haplotypes over inferred, but didn't work as intended\n",
    "# comparison = unpivoted.group_by(\"Id\", \"Gene\", \"Haplotype\", \"Haplotype Method\"\n",
    "# ).agg(\n",
    "#     pl.len(), pl.first(\"Sire\", \"Dam\"), \"Batch\",\n",
    "    # Since there can only be one \"Inferred\" (at least with how this has been handled so far)\n",
    "    # for a combination of Animal and Gene, we can just filter for \"Empirical\" to remove\n",
    "    # any \"Inferred\" entries that should also then have \"Empricial\" entries\n",
    "    # pl.when(pl.len() > 1)\n",
    "    # .then(pl.col(\"Haplotype\").filter(pl.col(\"Haplotype Method\") == \"Empirical\"))\n",
    "    # .otherwise(\"Haplotype\")\n",
    "    #pl.col(\"Haplotype\").filter(pl.col(\"Haplotype Method\") == \"Empirical\")\n",
    "#).filter(pl.col(\"len\") > 1 # TEST\n",
    "#)\n",
    "\n",
    "# Split empirical and inferred into separate tables\n",
    "# TODO: Take into account when there are multiple empirical haplotypes for a single animal and gene.\n",
    "# Using Debbie's compilation, there shouldn't be such cases, but there will be when I start processing\n",
    "# each of the old batches in their original form\n",
    "# empirical = unpivoted.filter(\n",
    "#     pl.col(\"Haplotype Method\") == \"Empirical\"\n",
    "# )\n",
    "# inferred = unpivoted.filter(\n",
    "#     pl.col(\"Haplotype Method\") == \"Inferred\"\n",
    "# )\n",
    "\n",
    "not_nulls = modified.filter(\n",
    "    ~(pl.col(\"Haplotype Method\") == [None, None])\n",
    ") \n",
    "\n",
    "nulls = modified.filter(\n",
    "    pl.col(\"Haplotype Method\") == [None, None]\n",
    ") \n",
    "\n",
    "# Keep only nulls that are not also empirical and then concatenate with empirical table\n",
    "concatenated = pl.concat([not_nulls, nulls.join(not_nulls, on=['Id', 'Gene'], how='anti')])\n",
    "\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8af9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Decide which to keep when there are multiple haplotypes recorded for same animal and gene\n",
    "# concatenated.group_by(\"Id\", \"Gene\").agg(pl.first(\"Sire\", \"Dam\"), \"Batch\", \"Haplotype\", \"Haplotype Method\").filter(\n",
    "#     pl.col(\"Haplotype\").list.len() > 1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with sire and dam haplotypes\n",
    "trios = concatenated.join(\n",
    "    # Join sire haplotypes\n",
    "    concatenated.select('Id', 'Gene', 'Diplotype'),\n",
    "        left_on=['Sire', 'Gene'], right_on=['Id', 'Gene'], how='left', suffix='_sire'\n",
    ").join(\n",
    "    # Join dam haplotypes\n",
    "    concatenated.select('Id', 'Gene', 'Diplotype'),\n",
    "        left_on=['Dam', 'Gene'], right_on=['Id', 'Gene'], how='left', suffix='_dam'\n",
    ").with_columns(\n",
    "    # Converts nulls to [null, null]\n",
    "    # TODO: Is there a way to set as array initially instead of coverting after?\n",
    "    pl.col(\"Diplotype_sire\").fill_null([None, None]).cast(pl.Array(pl.String, 2)),\n",
    "    pl.col(\"Diplotype_dam\").fill_null([None, None]).cast(pl.Array(pl.String, 2)),\n",
    ")\n",
    "\n",
    "trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Impute parents from offspring\n",
    "# TODO: Allow storing both Empirical and Inferred for the same haplotype\n",
    "# to be able to show extra confidence in the typing\n",
    "\n",
    "# Infer offspring haplotype when parent is homozygous\n",
    "inferred = trios.with_columns(\n",
    "    # Find alleles homozygous in parents\n",
    "    pl.when(pl.col(\"Diplotype_sire\").arr.get(0) == pl.col(\"Diplotype_sire\").arr.get(1)).then(\n",
    "        pl.col(\"Diplotype_sire\").arr.get(0))\n",
    "    .alias(\"Paternal Inference\"),\n",
    "    pl.when(pl.col(\"Diplotype_dam\").arr.get(0) == pl.col(\"Diplotype_dam\").arr.get(1)).then(\n",
    "        pl.col(\"Diplotype_dam\").arr.get(0))\n",
    "    .alias(\"Maternal Inference\"),\n",
    "    # Identify whether each parent is compatible with offspring\n",
    "    # TODO: Take into account where paternity and maternity might separately be True but not together\n",
    "    pl.when((pl.col(\"Diplotype_sire\").arr.get(0).is_in(pl.col(\"Diplotype\"))\n",
    "     | pl.col(\"Diplotype_sire\").arr.get(1).is_in(pl.col(\"Diplotype\"))\n",
    "    )).then(\n",
    "        True\n",
    "    ).when(pl.col(\"Diplotype\").arr.contains(None) | (pl.col(\"Diplotype_sire\") == [None, None])\n",
    "    ).then(\n",
    "        None\n",
    "    ).otherwise(\n",
    "        False\n",
    "    ).alias(\"Haplotypic Paternity\"),\n",
    "    pl.when((pl.col(\"Diplotype_dam\").arr.get(0).is_in(pl.col(\"Diplotype\"))\n",
    "     | pl.col(\"Diplotype_dam\").arr.get(1).is_in(pl.col(\"Diplotype\"))\n",
    "    )).then(\n",
    "        True\n",
    "    ).when(pl.col(\"Diplotype\").arr.contains(None) | (pl.col(\"Diplotype_dam\") == [None, None])\n",
    "    ).then(\n",
    "        None\n",
    "    ).otherwise(\n",
    "        False\n",
    "    ).alias(\"Haplotypic Maternity\")\n",
    ").with_columns(\n",
    "    # Create the inferred haplotype\n",
    "    pl.concat_arr([\n",
    "        pl.col(\"Paternal Inference\"),\n",
    "        pl.col(\"Maternal Inference\"),\n",
    "    ]).alias(\"Inferred Haplotype\")\n",
    ").drop(\"Paternal Inference\", \"Maternal Inference\"\n",
    ").with_columns(\n",
    "    # Combine existing empirical haplotypes with the inferred.\n",
    "    # This is done using set logic with Empirical + (Emprirical - Inferred).\n",
    "    # So, empirical haplotypes are given priority while also not duplicating them with inferred if they\n",
    "    # have the same haplotypes. Homozygous inferred remove the second copy but are added back in in the next `with_columns(...)`\n",
    "    pl.concat_list([pl.col(\"Diplotype\").arr.to_list(), pl.col(\"Inferred Haplotype\").arr.to_list().list.set_difference(\n",
    "        pl.col(\"Diplotype\").arr.to_list()\n",
    "    )]).list.drop_nulls(\n",
    "    ).alias(\"Empirical+Inferred\")\n",
    ").with_columns(\n",
    "    # Add back in duplicate haplotypes when inferred haplotypes are homozygous that were removed when treated as sets\n",
    "    pl.when(pl.col(\"Inferred Haplotype\").arr.get(0) == pl.col(\"Inferred Haplotype\").arr.get(1)).then(\n",
    "        pl.col(\"Empirical+Inferred\").list.concat(pl.col(\"Inferred Haplotype\").arr.get(0))\n",
    "    ).otherwise(\n",
    "        pl.col(\"Empirical+Inferred\")\n",
    "    ).alias(\"Empirical+Inferred\")\n",
    ").with_columns(\n",
    "    # Remove extra haplotypes, so that only two are kept.\n",
    "    # Can become less than two though if some one or both are missing\n",
    "    pl.col(\"Empirical+Inferred\").list.slice(0, 2).list.sort()\n",
    ").drop(\"Inferred Haplotype\"\n",
    ").with_columns(\n",
    "    # Add back in nulls when necessary to make two haplotypes\n",
    "    pl.when(pl.col(\"Empirical+Inferred\").list.len() == 0\n",
    "    ).then(\n",
    "        pl.lit([None, None])\n",
    "    ).when(pl.col(\"Empirical+Inferred\").list.len() == 1\n",
    "    ).then(\n",
    "        pl.col(\"Empirical+Inferred\").list.concat(pl.lit([None]))\n",
    "    ).otherwise(\n",
    "        pl.col(\"Empirical+Inferred\")\n",
    "    ).alias(\"Empirical+Inferred\")\n",
    ").with_columns(\n",
    "    # Determine which of the haplotypes are empirical and which are inferred\n",
    "    # by comparing whether the haplotype was one of the original haplotypes.\n",
    "    # The next `with_columns` will correct an exception\n",
    "    pl.when(pl.col(\"Empirical+Inferred\").list.get(0).is_in(pl.col(\"Diplotype\"))\n",
    "    ).then(\n",
    "        pl.lit(\"Empirical\")\n",
    "    ).when(~pl.col(\"Empirical+Inferred\").list.get(0).is_in(pl.col(\"Diplotype\"))\n",
    "    ).then(\n",
    "        pl.lit(\"Inferred\")\n",
    "    ).alias(\"Haplotype Status 1\"),\n",
    "    pl.when(pl.col(\"Empirical+Inferred\").list.get(1).is_in(pl.col(\"Diplotype\"))\n",
    "    ).then(\n",
    "        pl.lit(\"Empirical\")\n",
    "    ).when(~pl.col(\"Empirical+Inferred\").list.get(1).is_in(pl.col(\"Diplotype\"))\n",
    "    ).then(\n",
    "        pl.lit(\"Inferred\")\n",
    "    ).alias(\"Haplotype Status 2\"),\n",
    ").with_columns(\n",
    "    # Change one of two \"Empirical\"s back to \"Inferred\" if the new haplotype is homozygous\n",
    "    # while the old is heterozygous\n",
    "    pl.when(\n",
    "        # When the new haplotypes are homozygous, but the original are not\n",
    "        (pl.col(\"Empirical+Inferred\").list.get(0) == pl.col(\"Empirical+Inferred\").list.get(1))\n",
    "        & (pl.col(\"Diplotype\").arr.get(0) != pl.col(\"Diplotype\").arr.get(1))\n",
    "    ).then(\n",
    "        # Change the \"Empricial\" to \"Inferred\"\n",
    "        pl.lit(\"Inferred\")\n",
    "    ).otherwise(\n",
    "        pl.col(\"Haplotype Status 2\")\n",
    "    ).alias(\"Haplotype Status 2\")\n",
    ").with_columns(\n",
    "    pl.concat_list([\"Haplotype Status 1\", \"Haplotype Status 2\"]).alias(\"Haplotype Status\")\n",
    ").drop(\"Haplotype Status 1\", \"Haplotype Status 2\"\n",
    ").with_columns(\n",
    "    # Overwrite columns before inferrence\n",
    "    pl.col(\"Empirical+Inferred\").alias(\"Diplotype\"),\n",
    "    pl.col(\"Haplotype Status\").alias(\"Haplotype Method\")\n",
    ").drop(\"Empirical+Inferred\", \"Haplotype Status\")\n",
    "\n",
    "# Unfortunately, this doesn't work since a named column can't be used inside `eval`\n",
    "# .with_columns(\n",
    "#     pl.col(\"Haplotype\").arr.eval(\n",
    "#         pl.element() == pl.col(\"Paternal Inference\")\n",
    "#     ).alias(\"Paternal Mendelian Error\")\n",
    "# )\n",
    "\n",
    "inferred.filter(\n",
    "    # Remove unknowns\n",
    "    pl.col(\"Diplotype\") != [None, None]\n",
    ")#.write_excel(\"/master/abagwell/workspace/MHC/output/haplotypes_unpivoted.xlsx\")\n",
    "\n",
    "# # Shows which trios have Mendelian errors\n",
    "# inferred.filter(\n",
    "#     (pl.col(\"Haplotypic Paternity\") == False) | (pl.col(\"Haplotypic Maternity\") == False)\n",
    "# ).filter(\n",
    "#     pl.col(\"Gene\").is_in([\"MHC-A\", \"MHC-B\"])\n",
    "# ).sort(\"Id\", \"Gene\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checking trios\n",
    "individual = inferred.filter(pl.col(\"Dam\") == \"33932\"\n",
    ").filter(\n",
    "    pl.col(\"Gene\") == \"MHC-A\"\n",
    ").filter(\n",
    "    pl.col(\"Diplotype\") != [None, None]\n",
    ").filter(\n",
    "    pl.col(\"Haplotype Method\") == [\"Empirical\", \"Empirical\"]\n",
    ")\n",
    "individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read kinship\n",
    "# kinship = pl.read_csv(\"/master/abagwell/variant-analysis/results/rhesus/kinship/KING/WES3+WGS3_left_join.founders24.SNP.autosomal.kin\",\n",
    "# separator=\"\\t\", columns=[\"ID1\", \"ID2\", \"Kinship\", \"Error\"]).with_columns(\n",
    "#     # Find animal ID from longer sample name\n",
    "#     pl.col(\"ID1\").str.split(\"_\").list.get(0).str.slice(3),\n",
    "#     pl.col(\"ID2\").str.split(\"_\").list.get(0).str.slice(3),\n",
    "# )\n",
    "\n",
    "# Shows which trios have Mendelian errors and compare to kinship\n",
    "inconsistencies = inferred.filter(\n",
    "    (pl.col(\"Haplotypic Paternity\") == False) | (pl.col(\"Haplotypic Maternity\") == False)\n",
    ").filter(\n",
    "    pl.col(\"Gene\").is_in([\"MHC-A\", \"MHC-B\"])\n",
    ").sort(\"Id\", \"Gene\"\n",
    ")\n",
    "# ).with_columns(\n",
    "#     # Set IDs for comparison to kinship\n",
    "#     pl.when((pl.col(\"Haplotypic Paternity\") == False) & pl.col(\"Haplotypic Maternity\") == False\n",
    "#     ).then(\n",
    "#         pl.col(\"Id\")  # TODO: Not sure how to write if both parents don't appear correct\n",
    "#     ).when(pl.col(\"Haplotypic Paternity\") == False\n",
    "#     ).then(\n",
    "#        pl.col(\"Sire\")\n",
    "#     ).when(pl.col(\"Haplotypic Maternity\") == False\n",
    "#     ).then(\n",
    "#         pl.col(\"Dam\")\n",
    "#     ).alias(\"ID2\")\n",
    "# ).join(\n",
    "#     # Compare to kinship\n",
    "#     kinship, left_on=[\"Id\",\"ID2\"], right_on=[\"ID1\", \"ID2\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e164862",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = inconsistencies.filter(\n",
    "    #pl.col(\"Batch\").is_in([\"SNPRC22\", \"SNPRC23\"])\n",
    ")#.group_by(\"Id\").agg(pl.len())\n",
    "specific#.write_excel('/master/abagwell/workspace/MHC/output/inconsistent_haplotypes.SNPRC22-SNPRC23.xlsx')\n",
    "#specific.write_excel('/master/abagwell/workspace/MHC/output/inconsistent_haplotypes.all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of inferred vs empirical\n",
    "inferred.filter(\n",
    "    pl.col(\"Gene\").is_in([\"MHC-A\", \"MHC-B\"])\n",
    ").select(\"Haplotype Method\").explode(\"Haplotype Method\").group_by(\"Haplotype Method\").agg(pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee634d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique haplotypes.\n",
    "# Can be used to see if there are any abnormally named haplotypes that have not beeen accounted for\n",
    "inferred.select(\"Diplotype\").explode(\"Diplotype\").rename({\n",
    "    'Diplotype': 'Haplotype'\n",
    "}).unique().sort(\"Haplotype\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "inferred.select(\n",
    "    \"Id\", \"Gene\", \"Diplotype\", \"Haplotype Method\" # \"Trio Inconsistency\"\n",
    ").filter(\n",
    "    # Remove unknowns\n",
    "    pl.col(\"Diplotype\") != [None, None]\n",
    ").explode(\n",
    "    # Necessary to explode lists to be able to write as a TSV\n",
    "    \"Diplotype\", \"Haplotype Method\"\n",
    "# ).drop_nulls(\n",
    "#     # Remove rows without a known haplotype\n",
    "#     \"Haplotype\"\n",
    ").rename({\n",
    "    'Diplotype': 'Haplotype'\n",
    "}).sort(\"Id\", \"Gene\", \"Haplotype\"\n",
    ").with_columns(\n",
    "    # Add back parentheses when inferred\n",
    "    pl.when(\n",
    "        pl.col(\"Haplotype Method\") == \"Inferred\"\n",
    "    ).then(\n",
    "        pl.lit(\"(\") + pl.col(\"Haplotype\") + pl.lit(\")\")\n",
    "    ).otherwise(\n",
    "        pl.col(\"Haplotype\")\n",
    "    ).alias(\"Haplotype\")\n",
    ").drop(\"Haplotype Method\"\n",
    ")#.filter(pl.col(\"Haplotype\").str.contains(\"/\")).select(\"Haplotype\").unique()\n",
    "#.write_csv(\"/master/abagwell/workspace/MHC/output/haplotypes_unpivoted.diplotype_exploded.tsv\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repivot data. This is not for later steps\n",
    "repivoted = inferred.explode(\n",
    "    # Get only one haplotype per record\n",
    "    \"Diplotype\", \"Haplotype Method\"\n",
    ").rename({\n",
    "    'Diplotype': 'Haplotype'\n",
    "}).with_columns(\n",
    "    # Add back parentheses when inferred\n",
    "    pl.when(\n",
    "        pl.col(\"Haplotype Method\") == \"Inferred\"\n",
    "    ).then(\n",
    "        pl.lit(\"(\") + pl.col(\"Haplotype\") + pl.lit(\")\")\n",
    "    ).otherwise(\n",
    "        pl.col(\"Haplotype\")\n",
    "    ).alias(\"Haplotype\")\n",
    ").group_by(\n",
    "    \"Id\", \"Batch\", \"Gene\"\n",
    ").agg(\n",
    "    # Recreate the diplotype field\n",
    "    \"Haplotype\", pl.first(\"GS ID\")\n",
    ").rename({\n",
    "    'Haplotype': 'Diplotype'\n",
    "}).filter(\n",
    "    # Drop nulls diplotypes\n",
    "    pl.col(\"Diplotype\") != [None, None]\n",
    ").pivot(\n",
    "    # Pivot back to having each gene as a separate column, but this time with inferences\n",
    "    \"Gene\", index= [\"Id\", \"Batch\", \"GS ID\"], values=\"Diplotype\"\n",
    ").select(\n",
    "    # Sort columns\n",
    "    \"Id\", \"Batch\", \"GS ID\", \"MHC-A\", \"MHC-B\", \"MHC-DPA\", \"MHC-DPB\", \"MHC-DQA\", \"MHC-DQB\", \"MHC-DRB\",\n",
    ").sort(\"Id\")\n",
    "\n",
    "repivoted#.write_excel(\"/master/abagwell/workspace/MHC/output/haplotypes_pivoted.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of monitored alleles and their corresponding genes\n",
    "monitored_alleles = pl.DataFrame(\n",
    "    {\n",
    "        \"Gene\": [\"MHC-A\", \"MHC-B\", \"MHC-B\", \"MHC-B\"],\n",
    "        \"Monitored Allele\": [\"A001\", \"B003\", \"B008\", \"B017\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create status columns for the presence or absence of each monitored allele\n",
    "# using the existing table nomenclature. However, the previous table contains\n",
    "# more information and should become the new standard\n",
    "# Note: If such columns continue to be used in the future, names such as A1*001\n",
    "# should be used over A001.\n",
    "status = inferred.join(\n",
    "    # Split into separate rows for each monitored allele\n",
    "    monitored_alleles, on=\"Gene\"\n",
    ").explode(\"Diplotype\", \"Haplotype Method\"\n",
    ").rename({\n",
    "    'Diplotype': 'Haplotype'\n",
    "}).with_columns(\n",
    "    # Find monitored allele status is regards to each single haplotype\n",
    "    pl.when(pl.col(\"Haplotype\").str.contains(pl.col(\"Monitored Allele\"))).then(\n",
    "        pl.lit(True)\n",
    "    ).when(~pl.col(\"Haplotype\").str.contains(pl.col(\"Monitored Allele\"))).then(\n",
    "        pl.lit(False)\n",
    "    ).alias(\"Partial Allele Status\")\n",
    ").group_by(\n",
    "    # Recombine\n",
    "    \"Id\", \"Gene\", \"Monitored Allele\"\n",
    ").agg(\n",
    "    pl.first(\"Sire\", \"Dam\"), \"Haplotype\", \"Haplotype Method\", \"Partial Allele Status\"\n",
    ").rename({\n",
    "    'Haplotype': 'Diplotype'\n",
    "}).with_columns(\n",
    "    pl.when(\n",
    "        # Only one empirically true is needed to be \"POSITIVE\"\n",
    "        ((pl.col(\"Haplotype Method\").list.get(0) == \"Empirical\") & (pl.col(\"Partial Allele Status\").list.get(0) == True))\n",
    "        | ((pl.col(\"Haplotype Method\").list.get(1) == \"Empirical\") & (pl.col(\"Partial Allele Status\").list.get(1) == True))\n",
    "    ).then(\n",
    "        pl.lit(\"POSITIVE\")\n",
    "    ).when(\n",
    "        # Otherwise, only one inferred true is needed to be \"(POSITIVE)\"\n",
    "        ((pl.col(\"Haplotype Method\").list.get(0) == \"Inferred\") & (pl.col(\"Partial Allele Status\").list.get(0) == True))\n",
    "        | ((pl.col(\"Haplotype Method\").list.get(1) == \"Inferred\") & (pl.col(\"Partial Allele Status\").list.get(1) == True))\n",
    "    ).then(\n",
    "        pl.lit(\"(POSITIVE)\")\n",
    "    ).when(\n",
    "        # Otherwise, both must be empirically false to be \"NEGATIVE\"\n",
    "        ((pl.col(\"Haplotype Method\").list.get(0) == \"Empirical\") & (pl.col(\"Partial Allele Status\").list.get(0) == False))\n",
    "        & ((pl.col(\"Haplotype Method\").list.get(1) == \"Empirical\") & (pl.col(\"Partial Allele Status\").list.get(1) == False))\n",
    "    ).then(\n",
    "        pl.lit(\"NEGATIVE\")\n",
    "    ).when(\n",
    "        # Otherwise, both must be inferred false to be \"(NEGATIVE)\"\n",
    "        ((pl.col(\"Haplotype Method\").list.get(0) == \"Inferred\") & (pl.col(\"Partial Allele Status\").list.get(0) == False))\n",
    "        & ((pl.col(\"Haplotype Method\").list.get(1) == \"Inferred\") & (pl.col(\"Partial Allele Status\").list.get(1) == False))\n",
    "    ).then(\n",
    "        pl.lit(\"(NEGATIVE)\")\n",
    "    ).alias(\"Allele Status\")\n",
    ")\n",
    "\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific haplotypes have been inferred previously. But here, statuses are inferred.\n",
    "# That is, when all parent haplotypes are known and it is then known that the offspring\n",
    "# does not have one of the monitored alleles\n",
    "\n",
    "prev_height = 0\n",
    "cur_height = status.drop_nulls(\"Allele Status\").height\n",
    "\n",
    "# Each iteration is able to utilize inferred status from the previous iteration\n",
    "while cur_height > prev_height:\n",
    "    prev_height = cur_height\n",
    "    status = status.join(\n",
    "        # Join sire haplotypes\n",
    "        status.select('Id', 'Gene', 'Monitored Allele', 'Allele Status'),\n",
    "            left_on=['Sire', 'Gene', 'Monitored Allele'], right_on=['Id', 'Gene', 'Monitored Allele'], how='left', suffix='_sire'\n",
    "    ).join(\n",
    "        # Join dam haplotypes\n",
    "        status.select('Id', 'Gene', 'Monitored Allele', 'Allele Status'),\n",
    "            left_on=['Dam', 'Gene', 'Monitored Allele'], right_on=['Id', 'Gene', 'Monitored Allele'], how='left', suffix='_dam'\n",
    "    ).with_columns(\n",
    "        # Infer monitored allele status\n",
    "        # Any definite positives should have already been inferred,\n",
    "        # so this will serve to infer negatives\n",
    "        pl.when(\n",
    "            pl.col(\"Allele Status\").is_not_null()\n",
    "        ).then(\n",
    "            pl.col(\"Allele Status\")\n",
    "        ).otherwise(\n",
    "            pl.when(\n",
    "                ((pl.col(\"Allele Status_sire\") == \"NEGATIVE\") | (pl.col(\"Allele Status_sire\") == \"(NEGATIVE)\"))\n",
    "                & ((pl.col(\"Allele Status_dam\") == \"NEGATIVE\") | (pl.col(\"Allele Status_dam\") == \"(NEGATIVE)\"))\n",
    "            ).then(\n",
    "                pl.lit(\"(NEGATIVE)\")\n",
    "            )\n",
    "        ).alias(\"Allele Status\")\n",
    "    ).drop(\"Allele Status_sire\", \"Allele Status_dam\")\n",
    "\n",
    "    cur_height = status.drop_nulls(\"Allele Status\").height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one column for each monitored allele\n",
    "# This uses the column names that are currently used elsewhere\n",
    "final_status = status.pivot(\n",
    "    # Create columns for each monitored allele\n",
    "    \"Monitored Allele\",\n",
    "    values=\"Allele Status\",\n",
    "    #aggregate_function=\"first\",\n",
    "    index=[\"Id\", \"Sire\", \"Dam\"]\n",
    ").rename({\n",
    "    \"A001\": \"A001 Status\",\n",
    "    \"B003\": \"B003 Status\",\n",
    "    \"B008\": \"B008 Status\",\n",
    "    \"B017\": \"B017 Status\",}\n",
    ").sort(\"Id\").select(\n",
    "    # Sort statuses\n",
    "    \"Id\", \"A001 Status\", \"B003 Status\", \"B008 Status\", \"B017 Status\"\n",
    ").filter(\n",
    "    # Remove individuals that are null for all monitored alleles\n",
    "    ~(pl.col(\"A001 Status\").is_null() & pl.col(\"B003 Status\").is_null() & pl.col(\"B008 Status\").is_null() & pl.col(\"B017 Status\").is_null())\n",
    ")\n",
    "\n",
    "final_status#.write_csv(\"/master/abagwell/workspace/MHC/output/allele_statuses.tsv\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to format that database currently uses\n",
    "for_TAC = repivoted.join(\n",
    "    # Merge the two dataframe\n",
    "    final_status, on=\"Id\"\n",
    ").with_columns(\n",
    "    # A column that the database has, but that I'm going to ignore\n",
    "    pl.col('MHC-A').list.get(0).alias('Mamu-A Haplotype 1'),\n",
    "    pl.col('MHC-A').list.get(1).alias('Mamu-A Haplotype 2'),\n",
    "    pl.col('MHC-B').list.get(0).alias('Mamu-B Haplotype 1'),\n",
    "    pl.col('MHC-B').list.get(1).alias('Mamu-B Haplotype 2'),\n",
    "    pl.col('MHC-DPA').list.get(0).alias('Mamu-DPA Haplotype 1'),\n",
    "    pl.col('MHC-DPA').list.get(1).alias('Mamu-DPA Haplotype 2'),\n",
    "    pl.col('MHC-DPB').list.get(0).alias('Mamu-DPB Haplotype 1'),\n",
    "    pl.col('MHC-DPB').list.get(1).alias('Mamu-DPB Haplotype 2'),\n",
    "    pl.col('MHC-DQA').list.get(0).alias('Mamu-DQA Haplotype 1'),\n",
    "    pl.col('MHC-DQA').list.get(1).alias('Mamu-DQA Haplotype 2'),\n",
    "    pl.col('MHC-DQB').list.get(0).alias('Mamu-DQB Haplotype 1'),\n",
    "    pl.col('MHC-DQB').list.get(1).alias('Mamu-DQB Haplotype 2'),\n",
    "    pl.col('MHC-DRB').list.get(0).alias('Mamu-DRB Haplotype 1'),\n",
    "    pl.col('MHC-DRB').list.get(1).alias('Mamu-DRB Haplotype 2'),\n",
    ").rename({\n",
    "    'Id': 'ANIMAL ID',\n",
    "    'Batch': 'File Source',\n",
    "    'GS ID': 'OC ID',  # TODO: Need to correct the abnormally named GS IDs\n",
    "}).select(\n",
    "    \"ANIMAL ID\", \"File Source\", \"OC ID\",\n",
    "    \"Mamu-A Haplotype 1\", \"Mamu-A Haplotype 2\",\n",
    "    \"Mamu-B Haplotype 1\", \"Mamu-B Haplotype 2\",\n",
    "    \"A001 Status\", \"B003 Status\", \"B008 Status\", \"B017 Status\",\n",
    "    \"Mamu-DPA Haplotype 1\", \"Mamu-DPA Haplotype 2\",\n",
    "    \"Mamu-DPB Haplotype 1\", \"Mamu-DPB Haplotype 2\",\n",
    "    \"Mamu-DQA Haplotype 1\", \"Mamu-DQA Haplotype 2\",\n",
    "    \"Mamu-DQB Haplotype 1\", \"Mamu-DQB Haplotype 2\",\n",
    "    \"Mamu-DRB Haplotype 1\", \"Mamu-DRB Haplotype 2\",\n",
    ")\n",
    "\n",
    "for_TAC.write_csv(\"/master/abagwell/workspace/MHC/output/MHC_for_TAC.tsv\", separator=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
