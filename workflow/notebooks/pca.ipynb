{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Read config file\n",
    "configfile = \"/master/abagwell/workspace/github_project/variant-analysis/config/rhesus_old.yaml\"\n",
    "with open(configfile, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Read chromosomes\n",
    "with open(config[\"resources\"] + \"ref_fna/chromosomes.list\") as f:\n",
    "    chromosomes = f.read().splitlines()\n",
    "\n",
    "name = \"U42_WES.founders2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callsets = []\n",
    "# for chrom in chromosomes:\n",
    "vcf = config[\"results\"] + f\"genotypes/pass/{name}.SNP.autosomal.vcf.gz\"\n",
    "#vcf = config[\"results\"] + \"genotypes/pass/U42_WES.all2.SNP.autosomal.simplified.vcf.gz\"\n",
    "\n",
    "callset = allel.read_vcf(vcf, ['variants/CHROM', 'samples', 'calldata/GT'])\n",
    "\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# for chrom in range(1, 21):\n",
    "#     vcf = f\"/master/abagwell/variant-analysis/results/rhesus/genotypes/pass/U42_WES.founders.SNP.chr{chrom}.vcf.gz\"\n",
    "#     callset = allel.read_vcf(vcf, ['variants/CHROM', 'samples', 'calldata/GT'])\n",
    "#     df = pd.concat([df, callset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset[\"calldata/GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numpy seed\n",
    "numpy_seed = 889\n",
    "np.random.seed(numpy_seed)\n",
    "\n",
    "#chrom_filter = np.equal(callset['variants/CHROM'], '19')\n",
    "\n",
    "# Take genotypes from current chromosome\n",
    "#genotypes = allel.GenotypeArray(callset['calldata/GT'][chrom_filter])\n",
    "genotypes = allel.GenotypeArray(callset['calldata/GT'])\n",
    "\n",
    "# Allele counts\n",
    "ac = genotypes.count_alleles()[:]\n",
    "\n",
    "# Keep only biallelic SNPs\n",
    "filter = (ac.max_allele() == 1) & (ac[:, :2].min(axis=1) > 1)\n",
    "genotypes_filtered = genotypes.compress(filter, axis=0)\n",
    "\n",
    "# Make into 2D matrix where cells are number of non-reference alleles\n",
    "genotypes_counts = genotypes_filtered.to_n_alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(genotypes_counts, title):\n",
    "    m = allel.rogers_huff_r(genotypes_counts) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)\n",
    "\n",
    "plot_ld(genotypes_counts[:120], 'Figure 1. Pairwise LD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample number of SNPs used\n",
    "n = 100000  # number of SNPs to choose randomly\n",
    "\n",
    "vidx = np.random.choice(genotypes_counts.shape[0], n, replace=False)\n",
    "vidx.sort()\n",
    "gnr = genotypes_counts.take(vidx, axis=0)\n",
    "\n",
    "plot_ld(gnr[:120], 'Figure 1. Pairwise LD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LD pruning\n",
    "def ld_prune(genotypes_counts, size, step, threshold=.1, n_iter=1):\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(genotypes_counts, size=size, step=step, threshold=threshold)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = genotypes_counts.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        genotypes_counts= genotypes_counts.compress(loc_unlinked, axis=0)\n",
    "    return genotypes_counts\n",
    "\n",
    "gnu = ld_prune(gnr, size=500, step=200, threshold=.1, n_iter=5)\n",
    "\n",
    "plot_ld(gnu[:120], 'Figure 1. Pairwise LD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 164\n",
    "coords1, model1 = allel.pca(gnu, n_components=n_components, scaler='patterson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(coords1, columns = [f\"PC{n}\" for n in range(1,n_components+1)])\n",
    "#df[\"sample\"] = callset[\"samples\"]\n",
    "df.insert(0, \"indiv\", callset[\"samples\"])\n",
    "\n",
    "pl.from_pandas(df).write_csv(config[\"results\"] + \"pca/scikit-allel/\" + f\"{name}.pca.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Write explained variance\n",
    "with open(config[\"results\"] + \"pca/scikit-allel/\" + f\"{name}.variance.tsv\", \"w\") as f:\n",
    "    for line in list(model1.explained_variance_ratio_):\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rerun this lower half of the notebook in different environment since `allel` is not compatible with other packages\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import yaml\n",
    "\n",
    "# Read config file\n",
    "configfile = \"/master/abagwell/workspace/github_project/variant-analysis/config/rhesus_old.yaml\"\n",
    "with open(configfile, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# # Read chromosomes\n",
    "# with open(config[\"resources\"] + \"ref_fna/chromosomes.list\") as f:\n",
    "#     chromosomes = f.read().splitlines()\n",
    "\n",
    "# Load colors (keeping only those of the founding populations)\n",
    "# TODO: Generalize for when needing to remove colors or not\n",
    "colors = pl.read_csv(config[\"colors\"], separator=\"\\t\").filter(\n",
    "    pl.col(\"Cohort\").is_in([\"Conventional source\", \"Brooks source\", \"NEPRC source\"])\n",
    ")\n",
    "\n",
    "# TODO: Make this not have to be repeated\n",
    "numpy_seed = 889\n",
    "np.random.seed(numpy_seed)\n",
    "name = \"U42_WES.founders2\"\n",
    "\n",
    "# Read output files from scikit-allel step\n",
    "df = pl.read_csv(config[\"results\"] + \"pca/scikit-allel/\" + f\"{name}.pca.tsv\", separator=\"\\t\", schema_overrides={\"indiv\": pl.String})\n",
    "df_variance = pl.read_csv(config[\"results\"] + \"pca/scikit-allel/\" + f\"{name}.variance.tsv\", has_header=False, separator=\"\\t\", new_columns=[\"variance\"]\n",
    ").with_row_index(\"component\", offset=1\n",
    ").with_columns(\n",
    "    pl.col(\"variance\").mul(100).cast(pl.String).str.slice(0,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add batch information\n",
    "# runs_file = \"/master/abagwell/variant-analysis/resources/rhesus/samples/runs.WES.U42.list\"\n",
    "# runs = pl.read_csv(runs_file, separator=\"\\t\", has_header=False, new_columns=[\"batch/run\"]).with_columns(\n",
    "#     batch = pl.col(\"batch/run\").str.split(\"/\").list.get(0),\n",
    "#     #pl.col(\"batch/run\").str.split(\"/\").list.get(1).alias(\"sample\"),\n",
    "#     sample = pl.col(\"batch/run\").str.split(\"/\").list.get(1).str.split(\"_\").list.get(0),\n",
    "#     library = pl.col(\"batch/run\").str.split(\"/\").list.get(1).str.split(\"_\").list.get(1),\n",
    "# ).with_columns(\n",
    "#     sample_library = pl.concat_str([pl.col(\"sample\"), pl.col(\"library\")], separator=\"_\"),\n",
    "#     indiv = pl.col(\"sample\").str.slice(3)\n",
    "# ).group_by(\"indiv\").agg(pl.first(\"*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add batch information\n",
    "runs = pl.read_csv(config[\"runs\"], separator=\"\\t\", schema_overrides={\"indiv\": pl.String})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add colony info\n",
    "# Source 1\n",
    "\n",
    "colonies_file = config[\"resources\"] + \"pop/MML_groups_from_Martha.fixed7.tsv\"\n",
    "colonies = pl.read_csv(colonies_file, separator=\"\\t\", infer_schema_length=None)#.join(dates, on=\"Id\", how=\"left\")\n",
    "\n",
    "\n",
    "# df2 = pl.from_pandas(df).join(\n",
    "#     runs, how=\"inner\", left_on=\"indiv\", right_on=\"indiv\"\n",
    "# ).select(\"PC1\", \"PC2\", \"PC3\", \"indiv\", \"batch\"\n",
    "# )\n",
    "# \n",
    "\n",
    "df2 = colonies.join(df, how=\"inner\", left_on=\"Id\", right_on=\"indiv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Or source 2\n",
    "# colonies_file = \"/master/abagwell/variant-analysis/resources/rhesus/pop/colonies.tsv\"\n",
    "# colonies = pl.read_csv(colonies_file, separator=\"\\t\", infer_schema_length=None)\n",
    "\n",
    "# df2 = pl.from_pandas(df).join(runs, how=\"inner\", left_on=\"sample\", right_on=\"sample_library\"\n",
    "# ).select(\"PC1\", \"PC2\", \"PC3\", \"sample\", \"batch\").with_columns(\n",
    "#     Id = pl.col(\"sample\").str.split(\"_\").list.get(0).str.slice(3)\n",
    "# ).join(colonies, how=\"left\", on=\"Id\")\n",
    "\n",
    "# # merged = colony_demographics.join(Q, how=\"left\", left_on=\"Id\", right_on=\"#sample\"\n",
    "# # ).group_by(\"Year\", \"Colony\").agg(pl.count(\"Id\").alias(\"Count\"), pl.mean(\"Indian\"), pl.mean(\"Chinese\")).drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot PCA\n",
    "\n",
    "brush = alt.selection_interval()\n",
    "\n",
    "PC1_PC2 = alt.Chart(df2).mark_circle().encode(\n",
    "    alt.X(\"PC1\", title=f\"PC1 ({df_variance.filter(pl.col(\"component\") == 1)['variance'][0]}%)\"),\n",
    "    alt.Y(\"PC2\", title=f\"PC2 ({df_variance.filter(pl.col(\"component\") == 2)['variance'][0]}%)\"),\n",
    "    #color=alt.condition(brush, \"sample\", alt.value(\"lightgray\")),\n",
    "    #color=alt.Color(\"batch:N\", title=\"Batch\"),\n",
    "    color=alt.Color(\"Interval:N\", title=\"Cohort\").scale(\n",
    "        domain = list(colors[\"Cohort\"]),\n",
    "        range = list(colors[\"Color\"])\n",
    "    ),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"Id\", title=\"Indiv\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "PC2_PC3 = alt.Chart(df2).mark_circle().encode(\n",
    "    alt.Y(\"PC2\", title=f\"PC2 ({df_variance.filter(pl.col(\"component\") == 2)['variance'][0]}%)\"),\n",
    "    alt.X(\"PC3\", title=f\"PC3 ({df_variance.filter(pl.col(\"component\") == 3)['variance'][0]}%)\"),\n",
    "    #color=alt.Color(\"batch:N\", title=\"Batch\"),\n",
    "    color=alt.Color(\"Interval:N\", title=\"Cohort\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"Id\", title=\"Indiv\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "PC1_PC4 = alt.Chart(df2).mark_circle().encode(\n",
    "    alt.X(\"PC1\", title=f\"PC1 ({df_variance.filter(pl.col(\"component\") == 1)['variance'][0]}%)\"),\n",
    "    alt.Y(\"PC4\", title=f\"PC4 ({df_variance.filter(pl.col(\"component\") == 4)['variance'][0]}%)\"),\n",
    "    #color=alt.Color(\"batch:N\", title=\"Batch\"),\n",
    "    color=alt.Color(\"Interval:N\", title=\"Cohort\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"Id\", title=\"Indiv\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ((first) & (third | fifth)).add_params(\n",
    "#     brush\n",
    "# ).properties(\n",
    "#     title=\"Rhesus PCA\",\n",
    "# ).configure_title(\n",
    "#     anchor=\"middle\"\n",
    "# )\n",
    "\n",
    "(PC1_PC2).add_params(\n",
    "#(PC1_PC2 | PC2_PC3).add_params(\n",
    "    brush\n",
    ").properties(\n",
    "    title=\"PCA of Cohorts\",\n",
    ").configure_title(\n",
    "    anchor=\"middle\"\n",
    "#)#.save(f'/master/abagwell/figures/pca/U42.founders2.by_batch.pca{numpy_seed}.autosomal.html')\n",
    ")#.save(f'/master/abagwell/figures/final_plots/U42.founders2.by_origin_PC1-PC2.pca{numpy_seed}.autosomal.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Don't duplicate this line\n",
    "# n_components = 164\n",
    "\n",
    "\n",
    "# variance = pd.DataFrame(\n",
    "#     {\n",
    "#         \"n_pc\": range(1, n_components+1),\n",
    "#         \"variance\": model1.explained_variance_ratio_ * 100,\n",
    "#     }\n",
    "# )\n",
    "# variance[\"variance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(variance).mark_line(point=alt.OverlayMarkDef(filled=False, fill=\"white\")).encode(\n",
    "    alt.X(\"n_pc\", title=\"nth PC\"),\n",
    "    alt.Y(\"variance\", title=\"Percent of variance\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"variance\", title=\"Variance\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=900,\n",
    "    title=\"Principle Components by Percent of Variance\"\n",
    ")#.save(f'/master/abagwell/figures/pca/U42_founders2.pca{numpy_seed}.autosomal.variance.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot PCA\n",
    "import altair as alt\n",
    "\n",
    "brush = alt.selection_interval()\n",
    "\n",
    "first = alt.Chart(df).mark_circle().encode(\n",
    "    alt.X(\"PC1\", title=\"PC1\"),\n",
    "    alt.Y(\"PC2\", title=\"PC2\"),\n",
    "    color=alt.condition(brush, \"PC1\", alt.value(\"lightgray\")),\n",
    "    # tooltip=[\n",
    "    # alt.Tooltip(\"column_1\", title=\"Sample\")\n",
    "    # ],\n",
    ")\n",
    "\n",
    "second = alt.Chart(df).mark_circle().encode(\n",
    "    alt.X(\"PC3\", title=\"PC3\"),\n",
    "    alt.Y(\"PC4\", title=\"PC4\"),\n",
    "    color=alt.condition(brush, \"PC1\", alt.value(\"lightgray\"), legend=None),\n",
    "    # tooltip=[\n",
    "    # alt.Tooltip(\"column_1\", title=\"Sample\")\n",
    "    # ],\n",
    ")\n",
    "\n",
    "(first | second).add_params(\n",
    "    brush\n",
    ").properties(\n",
    "    title=\"Rhesus PCA\",\n",
    ").configure_title(\n",
    "    anchor=\"middle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UMAP\n",
    "import polars.selectors as cs\n",
    "import umap\n",
    "\n",
    "max_PC = 3\n",
    "\n",
    "#PCs = df.drop(\"indiv\")\n",
    "#PCs = df.select(\"PC1\", \"PC2\", \"PC3\")\n",
    "PCs = df2.select(cs.starts_with(\"PC\"))[:, 0:max_PC]\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(PCs)\n",
    "\n",
    "umap_df = pl.from_pandas(pd.DataFrame(embedding)).insert_column(0, df2[\"Id\"]).insert_column(0, df2[\"Interval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP\n",
    "\n",
    "## Plot PCA\n",
    "\n",
    "umap_plot = alt.Chart(umap_df).mark_circle().encode(\n",
    "    alt.X(\"0\", title=f\"UMAP1\"),\n",
    "    alt.Y(\"1\", title=f\"UMAP2\"),\n",
    "    color=alt.Color(\"Interval:N\", title=\"Cohort\").scale(\n",
    "        domain = list(colors[\"Cohort\"]),\n",
    "        range = list(colors[\"Color\"])\n",
    "    ),\n",
    "    # tooltip=[\n",
    "    #     alt.Tooltip(\"Id\", title=\"Indiv\")\n",
    "    # ],\n",
    ")\n",
    "\n",
    "\n",
    "umap_plot.properties(\n",
    "    #title=\"UMAP of Cohorts\",\n",
    "    title=\"UMAP of Founders\",\n",
    ").configure_title(\n",
    "    anchor=\"middle\"\n",
    ")#.save(f'/master/abagwell/figures/pca/{name}.by_origin_PC1-PC{max_PC}.umap{numpy_seed}.autosomal.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using output from `akt pca`\n",
    "import altair as alt\n",
    "import polars as pl\n",
    "\n",
    "path = config[\"results\"] + \"relatedness/pca/all_samples.SNP.pca.4.tsv\"\n",
    "\n",
    "\n",
    "data = pl.read_csv(path, separator=\"\\t\", has_header=False)\n",
    "# .filter(\n",
    "#     (pl.col(\"column_1\") == \"WES30009\") | (pl.col(\"column_1\") == \"WGS30009\")\n",
    "# )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot PCA\n",
    "\n",
    "brush = alt.selection_interval()\n",
    "\n",
    "first = alt.Chart(data.to_arrow().to_pandas()).mark_circle().encode(\n",
    "    alt.X(\"column_2\", title=\"PC1\"),\n",
    "    alt.Y(\"column_3\", title=\"PC2\"),\n",
    "    color=alt.condition(brush, \"column_1\", alt.value(\"lightgray\")),\n",
    "    tooltip=[\n",
    "    alt.Tooltip(\"column_1\", title=\"Sample\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "second = alt.Chart(data.to_arrow().to_pandas()).mark_circle().encode(\n",
    "    alt.X(\"column_4\", title=\"PC3\"),\n",
    "    alt.Y(\"column_5\", title=\"PC4\"),\n",
    "    color=alt.condition(brush, \"column_1\", alt.value(\"lightgray\"), legend=None),\n",
    "    tooltip=[\n",
    "    alt.Tooltip(\"column_1\", title=\"Sample\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "(first | second).add_params(\n",
    "    brush\n",
    ").properties(\n",
    "    title=\"Rhesus PCA\",\n",
    ").configure_title(\n",
    "    anchor=\"middle\"\n",
    ")#.save(\"rhesus_pca.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "callset = allel.read_vcf(vcf, ['variants/CHROM', 'variants/POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SNP-density plot\n",
    "import polars as pl\n",
    "\n",
    "# TODO: Generalize chromosome lengths (currently for rhesus Mmul_10)\n",
    "chromosome_lengths = [223_616_942, 196_197_964, 185_288_947, 169_963_040, 187_317_192, 179_085_566, 169_868_564, 145_679_320, 134_124_166, 99_517_758, 133_066_086, 130_043_856, 108_737_130, 128_056_306, 113_283_604, 79_627_064, 95_433_459, 74_474_043, 58_315_233, 77_137_495]  # For Mmul_10\n",
    "\n",
    "# Read VCFs. Not that this part takes a long time to run\n",
    "dfs_by_chromosome = []\n",
    "for idx, chrom in enumerate(chromosomes):\n",
    "    vcf = config[\"results\"] + f\"genotypes/pass/WGS/U42_WGS_WES.SNP.chr{chrom}.vcf.gz\"\n",
    "    df = pl.from_pandas(allel.vcf_to_dataframe(vcf, ['variants/CHROM', 'variants/POS'])).with_columns(\n",
    "    pl.col(\"POS\").floordiv(1_000_000)\n",
    "    ).group_by(\"CHROM\", \"POS\").agg(pl.len())\n",
    "    dfs_by_chromosome.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "plot_list = []\n",
    "for chrom, chrom_len, df in zip(chromosomes, chromosome_lengths, dfs_by_chromosome):\n",
    "    if chrom == \"1\":\n",
    "        axis = alt.Axis(labels=True)\n",
    "    else:\n",
    "        axis = alt.Axis(labels=False, ticks=False, title=\"\")\n",
    "    plot = alt.Chart(df).mark_line().encode(\n",
    "        alt.X('POS:Q', title=[\"Position (Gb)\"], axis=axis).scale(domainMax=chrom_len/1_000_000, clamp=True),\n",
    "        alt.Y('len', title=[\"SNP\", \"count\"]),\n",
    "        #alt.Row('variants/CHROM:O'),\n",
    "    ).properties(\n",
    "        #title=\"SNP Density\",\n",
    "        #title=f\"chr{int(chrom)}\",\n",
    "        title=alt.TitleParams(f'chr{int(chrom)}', orient=\"left\"),\n",
    "        height=50,\n",
    "        width=chromosome_lengths[int(chrom) - 1]/500000,\n",
    "        #header=alt.Header(labelOrient='bottom'),\n",
    "    )\n",
    "    plot_list.append(plot.resolve_scale(y='shared'))\n",
    "plot_list.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.vconcat(*plot_list, spacing=3).configure_mark(\n",
    "        #color=\"orange\",\n",
    "    )#.save(\"/master/abagwell/figures/roh/SNPRC.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing in a simple plot\n",
    "#import altair as alt\n",
    "\n",
    "\n",
    "alt.Chart(pl.concat(dfs_by_chromosome)).mark_line().encode(\n",
    "    alt.X('POS:Q', title=[\"Position\", \"(Gb)\"]),#.scale(domainMax=chrom_len/1_000_000, clamp=True),\n",
    "    alt.Y('len', title=\"SNP count\"),\n",
    "    alt.Row('CHROM:O'),\n",
    ").properties(\n",
    "    #title=\"SNP Density\",\n",
    "    title=f\"chr{int(chrom)}\",\n",
    "    height=50,\n",
    "    width=800,\n",
    "    #width=chromosome_lengths[int(chrom) - 1]/190000,\n",
    ")\n",
    "\n",
    "#plot_list.append(plot.resolve_scale(y='shared'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat(dfs_by_chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
